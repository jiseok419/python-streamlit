
import my_yt_trans
import my_text_sum 
import streamlit as st
import tiktoken
import textwrap

st.set_page_config(page_title="youtube_summary_app", page_icon="ğŸ“ˆ")

def calc_token_num(text, model="gpt-3.5-turbo"):
    enc = tiktoken.encoding_for_model(model)
    encoded_list = enc.encode(text)
    token_num= len(encoded_list)  
    
    return token_num

def divide_text(text, token_num):
    req_max_token = 2000 
    
    divide_num = int(token_num/req_max_token) + 1 
    divide_char_num = int(len(text) / divide_num)
    divide_width =  divide_char_num + 20

    divided_text_list = textwrap.wrap(text, width=divide_width)
    
    return divide_num, divided_text_list


def summarize_youtube_video(video_url, selected_lang, trans_method):
    if selected_lang == 'ì˜ì–´':
        lang = 'en' 
    else:
        lang = 'ko' 
    
    st.video(video_url, format='video/mp4')
    
    _, yt_title, _, _, yt_duration = my_yt_trans.get_youtube_video_info(video_url)
    st.write(f"[ì œëª©] {yt_title}, [ê¸¸ì´(ë¶„:ì´ˆ)] {yt_duration}")
    
    yt_transcript = my_yt_trans.get_transcript_from_youtube(video_url, lang)

    token_num = calc_token_num(yt_transcript)
    
    div_num, divided_yt_transcripts = divide_text(yt_transcript, token_num)

    st.write("ìœ íŠœë¸Œ ë™ì˜ìƒ ë‚´ìš© ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.") 
    
    summaries = []
    for divided_yt_transcript in divided_yt_transcripts:
        summary = my_text_sum.summarize_text(divided_yt_transcript, lang)
        summaries.append(summary)
        
    _, final_summary = my_text_sum.summarize_text_final(summaries, lang)

    if selected_lang == 'ì˜ì–´':
        shorten_num = 200 
    else:
        shorten_num = 1000 
        
    shorten_final_summary = textwrap.shorten(final_summary, shorten_num, placeholder=' [..ì´í•˜ ìƒëµ..]')
    st.write("- ìë§‰ ìš”ì•½(ì¶•ì•½):", shorten_final_summary) 

    if selected_lang == 'ì˜ì–´': 
        if trans_method == 'OpenAI':
            trans_result = my_text_sum.traslate_english_to_korean_using_openAI(final_summary)
        elif trans_method == 'DeepL':
            trans_result = my_text_sum.traslate_english_to_korean_using_deepL(final_summary)

        shorten_trans_result = textwrap.shorten(trans_result, 1000 ,placeholder=' [..ì´í•˜ ìƒëµ..]')
        st.write("- í•œêµ­ì–´ ìš”ì•½(ì¶•ì•½):", shorten_trans_result) 
        
def button_callback():
    st.session_state['input'] = ""
    
st.title("ìš”ì•½ ì„¤ì • ")
url_text = st.text_input("ìœ íŠœë¸Œ ë™ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”.", key="input")

clicked_for_clear = st.button('URL ì…ë ¥ ë‚´ìš© ì§€ìš°ê¸°',  on_click=button_callback)

yt_lang = st.radio('ìœ íŠœë¸Œ ë™ì˜ìƒ ì–¸ì–´ ì„ íƒ', ['í•œêµ­ì–´', 'ì˜ì–´'], index=1, horizontal=True)
    
if yt_lang == 'ì˜ì–´':
    trans_method = st.radio('ë²ˆì—­ ë°©ë²• ì„ íƒ', ['OpenAI', 'DeepL'], index=1, horizontal=True)
else:
    trans_method = ""

clicked_for_sum = st.button('ë™ì˜ìƒ ë‚´ìš© ìš”ì•½')

st.title("ìœ íŠœë¸Œ ë™ì˜ìƒ ìš”ì•½")

if url_text and clicked_for_sum: 
    yt_video_url = url_text.strip()
    summarize_youtube_video(yt_video_url, yt_lang, trans_method)
